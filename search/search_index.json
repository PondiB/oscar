{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction OSCAR is a framework to efficiently support on-premises FaaS (Functions as a Service) for general-purpose file-processing computing applications. It represents the porting to an on-premises scenario of the SCAR framework , which supports a High Throughput Computing Programming Model to create highly-parallel event-driven file-processing serverless applications that execute on customized runtime environments provided by Docker containers run on AWS Lambda. Goal Users upload files to a bucket and this automatically triggers the execution of parallel invocations to a function responsible for processing each file. Output files are delivered into an output bucket for the convenience of the user. Highly scalable HTTP-based endpoints can also be offered in order to expose a generic application. An user-provided shell script is executed inside the container run from the user-defined Docker image in order to achieve the right execution environment for the application. Components OSCAR runs on an elastic Kubernetes cluster that is deployed using: EC3 , an open-source tool to deploy compute clusters that can horizontally scale in terms of number of nodes with multiple plugins. IM , an open-source virtual infrastructure provisioning tool for multi-Clouds. CLUES , an elasticity manager that horizontally scales in and out the number of nodes of the Kubernetes cluster according to the workload. The following components are deployed inside the Kubernetes cluster in order to support the OSCAR platform: MinIO , a high performance distributed object storage server that provides an API compatible with S3. OpenFaaS , a FaaS platform that allows creating functions executed via HTTP requests. OSCAR, the main application, responsible for the management of the services and the integration of the different components to support event-driven serverless computing for file processing. It includes a web-based GUI aimed at end users to facilitate interaction with OSCAR. As external storage providers, the following services can be used: External MinIO servers, which may be in clusters other than the platform. Amazon S3 , the Amazon's object storage service that offers industry-leading scalability, data availability, security, and performance in the public Cloud. Onedata , the global data access solution for science used in the EGI Federated Cloud . An OSCAR cluster can be accessed via its REST API , the web-based UI and the the command-line interface provided by oscar-cli .","title":"Introduction"},{"location":"#introduction","text":"OSCAR is a framework to efficiently support on-premises FaaS (Functions as a Service) for general-purpose file-processing computing applications. It represents the porting to an on-premises scenario of the SCAR framework , which supports a High Throughput Computing Programming Model to create highly-parallel event-driven file-processing serverless applications that execute on customized runtime environments provided by Docker containers run on AWS Lambda.","title":"Introduction"},{"location":"#goal","text":"Users upload files to a bucket and this automatically triggers the execution of parallel invocations to a function responsible for processing each file. Output files are delivered into an output bucket for the convenience of the user. Highly scalable HTTP-based endpoints can also be offered in order to expose a generic application. An user-provided shell script is executed inside the container run from the user-defined Docker image in order to achieve the right execution environment for the application.","title":"Goal"},{"location":"#components","text":"OSCAR runs on an elastic Kubernetes cluster that is deployed using: EC3 , an open-source tool to deploy compute clusters that can horizontally scale in terms of number of nodes with multiple plugins. IM , an open-source virtual infrastructure provisioning tool for multi-Clouds. CLUES , an elasticity manager that horizontally scales in and out the number of nodes of the Kubernetes cluster according to the workload. The following components are deployed inside the Kubernetes cluster in order to support the OSCAR platform: MinIO , a high performance distributed object storage server that provides an API compatible with S3. OpenFaaS , a FaaS platform that allows creating functions executed via HTTP requests. OSCAR, the main application, responsible for the management of the services and the integration of the different components to support event-driven serverless computing for file processing. It includes a web-based GUI aimed at end users to facilitate interaction with OSCAR. As external storage providers, the following services can be used: External MinIO servers, which may be in clusters other than the platform. Amazon S3 , the Amazon's object storage service that offers industry-leading scalability, data availability, security, and performance in the public Cloud. Onedata , the global data access solution for science used in the EGI Federated Cloud . An OSCAR cluster can be accessed via its REST API , the web-based UI and the the command-line interface provided by oscar-cli .","title":"Components"},{"location":"about/","text":"About OSCAR has been developed by the Grid and High Performance Computing Group (GRyCAP) at the Instituto de Instrumentaci\u00f3n para Imagen Molecular (I3M) from the Universitat Polit\u00e8cnica de Val\u00e8ncia (UPV) . This development is partially funded by the EGI Strategic and Innovation Fund and it can be deployed in the EGI Platform through the EGI Applications on Demand portal . Contact If you have any trouble please open an issue or email us .","title":"About"},{"location":"about/#about","text":"OSCAR has been developed by the Grid and High Performance Computing Group (GRyCAP) at the Instituto de Instrumentaci\u00f3n para Imagen Molecular (I3M) from the Universitat Polit\u00e8cnica de Val\u00e8ncia (UPV) . This development is partially funded by the EGI Strategic and Innovation Fund and it can be deployed in the EGI Platform through the EGI Applications on Demand portal .","title":"About"},{"location":"about/#contact","text":"If you have any trouble please open an issue or email us .","title":"Contact"},{"location":"api/","text":"OpenAPI Specification OSCAR exposes a secure REST API available at the Kubernetes master's node IP through an ingress. This API has been described following the OpenAPI Specification and it can be consulted bellow. const ui = SwaggerUIBundle({ url: 'api.yaml', dom_id: '#swagger-ui', })","title":"OpenAPI Specification"},{"location":"api/#openapi-specification","text":"OSCAR exposes a secure REST API available at the Kubernetes master's node IP through an ingress. This API has been described following the OpenAPI Specification and it can be consulted bellow. const ui = SwaggerUIBundle({ url: 'api.yaml', dom_id: '#swagger-ui', })","title":"OpenAPI Specification"},{"location":"deploy-ec3/","text":"Deployment with EC3 In order to deploy an elastic Kubernetes cluster with the OSCAR platform, you must use EC3 , a tool that deploys elastic virtual clusters. EC3 uses the Infrastructure Manager (IM) to deploy such clusters on multiple Cloud back-ends. The installation details can be found here , though this section includes the relevant information to get you started. Prepare EC3 Clone the EC3 repository: git clone https://github.com/grycap/ec3 Download the OSCAR template into the ec3/templates folder: cd ec3 wget -P templates https://raw.githubusercontent.com/grycap/oscar/master/templates/oscar.radl Create an auth.txt authorization file with valid credentials to access your Cloud provider. As an example, to deploy on an OpenNebula-based Cloud site the contents of the file would be: type = OpenNebula; host = opennebula-host:2633; username = your-user; password = you-password Modify the corresponding RADL template in order to determine the appropriate configuration for your deployment: Virtual Machine Image identifiers Hardware Configuration As an example, to deploy in OpenNebula, one would modify the ubuntu-opennebula.radl (or create a new one). Deploy the cluster To deploy the cluster, execute: ./ec3 launch oscar-cluster oscar ubuntu-opennebula -a auth.txt This will take several minutes until the Kubernetes cluster and all the required services have been deployed. You will obtain the IP of the front-end of the cluster and a confirmation message that the front-end is ready. Notice that it will still take few minutes before the services in the Kubernetes cluster are up & running. Check the cluster state The cluster will be fully configured when all the Kubernetes pods are in the Running state. ./ec3 ssh oscar-cluster sudo kubectl get pods --all-namespaces Notice that initially only the front-end node of the cluster is deployed. As soon as the OSCAR framework is deployed, together with its services, the CLUES elasticity manager powers on a new (working) node on which these services will be run. You can see the status of the provisioned node(s) by issuing: clues status which obtains: node state enabled time stable (cpu,mem) used (cpu,mem) total ----------------------------------------------------------------------------------------------- wn1.localdomain used enabled 00h00'49\" 0.0,825229312 1,1992404992 wn2.localdomain off enabled 00h06'43\" 0,0 1,1073741824 wn3.localdomain off enabled 00h06'43\" 0,0 1,1073741824 wn4.localdomain off enabled 00h06'43\" 0,0 1,1073741824 wn5.localdomain off enabled 00h06'43\" 0,0 1,1073741824 The working nodes transition from off to powon and, finally, to the used status. Default Service Endpoints Once the OSCAR framework is running on the Kubernetes cluster, the endpoints described in the following table should be available. Most of the passwords/tokens are dynamically generated at deployment time and made available in the /var/tmp folder of the front-end node of the cluster. Service Endpoint Default User Password File OSCAR https://{KUBE} oscar oscar_password MinIO https://{KUBE}:30300 minio minio_secret_key OpenFaaS http://{KUBE}:31112 admin gw_password Kubernetes API https://{KUBE}:6443 tokenpass Kube. Dashboard https://{KUBE}:30443 dashboard_token Note that {KUBE} refers to the public IP of the front-end of the Kubernetes cluster. For example, to get the OSCAR password, you can execute: ./ec3 ssh oscar-cluster cat /var/tmp/oscar_password","title":"Deployment with EC3"},{"location":"deploy-ec3/#deployment-with-ec3","text":"In order to deploy an elastic Kubernetes cluster with the OSCAR platform, you must use EC3 , a tool that deploys elastic virtual clusters. EC3 uses the Infrastructure Manager (IM) to deploy such clusters on multiple Cloud back-ends. The installation details can be found here , though this section includes the relevant information to get you started.","title":"Deployment with EC3"},{"location":"deploy-ec3/#prepare-ec3","text":"Clone the EC3 repository: git clone https://github.com/grycap/ec3 Download the OSCAR template into the ec3/templates folder: cd ec3 wget -P templates https://raw.githubusercontent.com/grycap/oscar/master/templates/oscar.radl Create an auth.txt authorization file with valid credentials to access your Cloud provider. As an example, to deploy on an OpenNebula-based Cloud site the contents of the file would be: type = OpenNebula; host = opennebula-host:2633; username = your-user; password = you-password Modify the corresponding RADL template in order to determine the appropriate configuration for your deployment: Virtual Machine Image identifiers Hardware Configuration As an example, to deploy in OpenNebula, one would modify the ubuntu-opennebula.radl (or create a new one).","title":"Prepare EC3"},{"location":"deploy-ec3/#deploy-the-cluster","text":"To deploy the cluster, execute: ./ec3 launch oscar-cluster oscar ubuntu-opennebula -a auth.txt This will take several minutes until the Kubernetes cluster and all the required services have been deployed. You will obtain the IP of the front-end of the cluster and a confirmation message that the front-end is ready. Notice that it will still take few minutes before the services in the Kubernetes cluster are up & running.","title":"Deploy the cluster"},{"location":"deploy-ec3/#check-the-cluster-state","text":"The cluster will be fully configured when all the Kubernetes pods are in the Running state. ./ec3 ssh oscar-cluster sudo kubectl get pods --all-namespaces Notice that initially only the front-end node of the cluster is deployed. As soon as the OSCAR framework is deployed, together with its services, the CLUES elasticity manager powers on a new (working) node on which these services will be run. You can see the status of the provisioned node(s) by issuing: clues status which obtains: node state enabled time stable (cpu,mem) used (cpu,mem) total ----------------------------------------------------------------------------------------------- wn1.localdomain used enabled 00h00'49\" 0.0,825229312 1,1992404992 wn2.localdomain off enabled 00h06'43\" 0,0 1,1073741824 wn3.localdomain off enabled 00h06'43\" 0,0 1,1073741824 wn4.localdomain off enabled 00h06'43\" 0,0 1,1073741824 wn5.localdomain off enabled 00h06'43\" 0,0 1,1073741824 The working nodes transition from off to powon and, finally, to the used status.","title":"Check the cluster state"},{"location":"deploy-ec3/#default-service-endpoints","text":"Once the OSCAR framework is running on the Kubernetes cluster, the endpoints described in the following table should be available. Most of the passwords/tokens are dynamically generated at deployment time and made available in the /var/tmp folder of the front-end node of the cluster. Service Endpoint Default User Password File OSCAR https://{KUBE} oscar oscar_password MinIO https://{KUBE}:30300 minio minio_secret_key OpenFaaS http://{KUBE}:31112 admin gw_password Kubernetes API https://{KUBE}:6443 tokenpass Kube. Dashboard https://{KUBE}:30443 dashboard_token Note that {KUBE} refers to the public IP of the front-end of the Kubernetes cluster. For example, to get the OSCAR password, you can execute: ./ec3 ssh oscar-cluster cat /var/tmp/oscar_password","title":"Default Service Endpoints"},{"location":"deploy-helm/","text":"Deployment on an existing Kubernetes cluster using Helm OSCAR can also be deployed on any existing Kubernetes cluster through its helm chart . However, to make the platform work properly, the following dependencies must be satisfied A StorageClass with the ReadWriteMany access mode must be configured in the cluster for the creation of the persistent volume mounted on the service containers. For this purpose, we use the Kubernetes NFS-Client Provisioner , but there are other volume plugins that support this access mode. MinIO must be deployed and properly configured in the cluster. Its helm chart can be used for this purpose. It is important to configure it properly to have access from inside and outside the cluster, as the OSCAR's web interface connects directly to its API. In the OSCAR helm chart, you must indicate the values corresponding to its credentials and endpoint.","title":"Deployment with Helm"},{"location":"deploy-helm/#deployment-on-an-existing-kubernetes-cluster-using-helm","text":"OSCAR can also be deployed on any existing Kubernetes cluster through its helm chart . However, to make the platform work properly, the following dependencies must be satisfied A StorageClass with the ReadWriteMany access mode must be configured in the cluster for the creation of the persistent volume mounted on the service containers. For this purpose, we use the Kubernetes NFS-Client Provisioner , but there are other volume plugins that support this access mode. MinIO must be deployed and properly configured in the cluster. Its helm chart can be used for this purpose. It is important to configure it properly to have access from inside and outside the cluster, as the OSCAR's web interface connects directly to its API. In the OSCAR helm chart, you must indicate the values corresponding to its credentials and endpoint.","title":"Deployment on an existing Kubernetes cluster using Helm"},{"location":"deploy-im-dashboard/","text":"Deployment with the IM Dashboard An OSCAR cluster can be easily deployed on multiple Cloud back-ends without requiring any installation by using the Infrastructure Manager 's Dashboard ( IM Dashboard ). This is a managed service provided by the GRyCAP research group at the Universitat Polit\u00e8cnica de Val\u00e8ncia to deploy customized virtual infrastructures across many Cloud providers. Using the IM Dashboard is the easiest and most convenient approach to deploy an OSCAR cluster. It also automatically allocates a DNS entry and TLS certificates to support HTTPS-based access to the OSCAR cluster and companion services (e.g. MinIO). This example shows how to deploy an OSCAR cluster on Amazon Web Services (AWS) with two nodes. Thanks to the IM, the very same procedure applies to deploy the OSCAR cluster in an on-premises Cloud (such as OpenStack) or any other Cloud provider supported by the IM. These are the steps: Access the IM Dashboard You will need to authenticate via EGI Check-In , which supports mutiple Identity Providers (IdP). Configure the Cloud Credentials Once logged in, you need to define the access credentials to the Cloud on which the OSCAR cluster will be deployed. These should be temporary credentials under the principle of least privilege (PoLP) . In our case we indicate an identifier for the set of credentials, the Access Key ID and the Secret Access Key for an IAM user that has privileges to deploy Virtual Machines in Amazon EC2 . Select the OSCAR template Customize and deploy the OSCAR cluster In this panel you can specify the number of Working Nodes (WNs) of the cluster together with the computational requirements for each node. We leave the default values. In this panel, specify the passwords to be employed to access the Kubernetes Web UI (Dashboard), to access the OSCAR web UI and to access the MinIO dashboard. These tokens can also be used for programmatic access to the respective services. Now, choose the Cloud provider. The ID specified when creating the Cloud credentials will be shown. You will also need to specify the Amazon Machine Image (AMI) identifier . We chose an AMI based on Ubuntu 20.04 provided by Canonical whose identifier for the us-east-1 region is: ami-09e67e426f25ce0d7 NOTE: You should obtain the AMI identifier for the latest version of the OS. This way, security patches will be already installed. You can obtain this AMI identifier from the AWS Marketplace or the Amazon EC2 service. Give the infrastructure a name and press \"Submit\". Check the status of the deployment OSCAR cluster You will see that the OSCAR cluster is being deployed and the infrastructure reaches the status \"running\". The process will not finish until it reaches the state \"configured\". If you are interested in understanding what is happening under the hood you can see the logs: Accessing the OSCAR cluster Once reached the \"configured\" state, see the \"Outputs\" to obtain the different endpoints: The OSCAR UI can be accessed with the username oscar and the password you specified at deployment time. The MinIO UI can be accessed with the username minio and the password you specified at deployment time. The Kubernetes Dashboard can be accessed with the token you specified at deployment time. You can obtain statistics about the Kubernetes cluster: Terminating the OSCAR cluster You can terminate the OSCAR cluster from the IM Dashboard:","title":"Deployment with IM Dashboard"},{"location":"deploy-im-dashboard/#deployment-with-the-im-dashboard","text":"An OSCAR cluster can be easily deployed on multiple Cloud back-ends without requiring any installation by using the Infrastructure Manager 's Dashboard ( IM Dashboard ). This is a managed service provided by the GRyCAP research group at the Universitat Polit\u00e8cnica de Val\u00e8ncia to deploy customized virtual infrastructures across many Cloud providers. Using the IM Dashboard is the easiest and most convenient approach to deploy an OSCAR cluster. It also automatically allocates a DNS entry and TLS certificates to support HTTPS-based access to the OSCAR cluster and companion services (e.g. MinIO). This example shows how to deploy an OSCAR cluster on Amazon Web Services (AWS) with two nodes. Thanks to the IM, the very same procedure applies to deploy the OSCAR cluster in an on-premises Cloud (such as OpenStack) or any other Cloud provider supported by the IM. These are the steps: Access the IM Dashboard You will need to authenticate via EGI Check-In , which supports mutiple Identity Providers (IdP). Configure the Cloud Credentials Once logged in, you need to define the access credentials to the Cloud on which the OSCAR cluster will be deployed. These should be temporary credentials under the principle of least privilege (PoLP) . In our case we indicate an identifier for the set of credentials, the Access Key ID and the Secret Access Key for an IAM user that has privileges to deploy Virtual Machines in Amazon EC2 . Select the OSCAR template Customize and deploy the OSCAR cluster In this panel you can specify the number of Working Nodes (WNs) of the cluster together with the computational requirements for each node. We leave the default values. In this panel, specify the passwords to be employed to access the Kubernetes Web UI (Dashboard), to access the OSCAR web UI and to access the MinIO dashboard. These tokens can also be used for programmatic access to the respective services. Now, choose the Cloud provider. The ID specified when creating the Cloud credentials will be shown. You will also need to specify the Amazon Machine Image (AMI) identifier . We chose an AMI based on Ubuntu 20.04 provided by Canonical whose identifier for the us-east-1 region is: ami-09e67e426f25ce0d7 NOTE: You should obtain the AMI identifier for the latest version of the OS. This way, security patches will be already installed. You can obtain this AMI identifier from the AWS Marketplace or the Amazon EC2 service. Give the infrastructure a name and press \"Submit\". Check the status of the deployment OSCAR cluster You will see that the OSCAR cluster is being deployed and the infrastructure reaches the status \"running\". The process will not finish until it reaches the state \"configured\". If you are interested in understanding what is happening under the hood you can see the logs: Accessing the OSCAR cluster Once reached the \"configured\" state, see the \"Outputs\" to obtain the different endpoints: The OSCAR UI can be accessed with the username oscar and the password you specified at deployment time. The MinIO UI can be accessed with the username minio and the password you specified at deployment time. The Kubernetes Dashboard can be accessed with the token you specified at deployment time. You can obtain statistics about the Kubernetes cluster: Terminating the OSCAR cluster You can terminate the OSCAR cluster from the IM Dashboard:","title":"Deployment with the IM Dashboard"},{"location":"egi-integration/","text":"Integration with the EGI Federated Cloud EGI is a federation of many cloud providers and hundreds of data centres, spread across Europe and worldwide that delivers advanced computing services to support scientists, multinational projects and research infrastructures. The EGI Federated Cloud is an IaaS-type cloud, made of academic private clouds and virtualised resources and built around open standards. Its development is driven by requirements of the scientific communities. EGI Applications on Demand: EC3 Portal The OSCAR platform can be deployed on the EGI Federated Cloud resources through the EC3 Portal available in the EGI Applications on Demand service. The EC3 Web Interface documentation can be followed in order to deploy the platform. Remember to pick \"OSCAR\" as the Local Resource Management System (LRMS). EGI DataHub EGI DataHub , based on Onedata , provides a global data access solution for science. Integrated with the EGI AAI, it allows users to have Onedata spaces supported by providers across Europe for replicated storage and on-demand caching. EGI DataHub can be used as an output storage provider for OSCAR, allowing users to store the resulting files of their OSCAR services on a Onedata space. This can be done thanks to the FaaS Supervisor . Used in OSCAR and SCAR , responsible for managing the data Input/Output and the user code execution. To deploy a function with Onedata as output storage provider you only have to specify an identifier, the URL of the Oneprovider host, your access token and the name of your Onedata space in the \"Storage\" tab of the service creation wizard: And the path where you want to store the files in the \"OUTPUTS\" tab: This means that scientists can store their output files on their Onedata space in the EGI DataHub for long-time persistence and easy sharing of experimental results between researchers.","title":"Integration with EGI"},{"location":"egi-integration/#integration-with-the-egi-federated-cloud","text":"EGI is a federation of many cloud providers and hundreds of data centres, spread across Europe and worldwide that delivers advanced computing services to support scientists, multinational projects and research infrastructures. The EGI Federated Cloud is an IaaS-type cloud, made of academic private clouds and virtualised resources and built around open standards. Its development is driven by requirements of the scientific communities.","title":"Integration with the EGI Federated Cloud"},{"location":"egi-integration/#egi-applications-on-demand-ec3-portal","text":"The OSCAR platform can be deployed on the EGI Federated Cloud resources through the EC3 Portal available in the EGI Applications on Demand service. The EC3 Web Interface documentation can be followed in order to deploy the platform. Remember to pick \"OSCAR\" as the Local Resource Management System (LRMS).","title":"EGI Applications on Demand: EC3 Portal"},{"location":"egi-integration/#egi-datahub","text":"EGI DataHub , based on Onedata , provides a global data access solution for science. Integrated with the EGI AAI, it allows users to have Onedata spaces supported by providers across Europe for replicated storage and on-demand caching. EGI DataHub can be used as an output storage provider for OSCAR, allowing users to store the resulting files of their OSCAR services on a Onedata space. This can be done thanks to the FaaS Supervisor . Used in OSCAR and SCAR , responsible for managing the data Input/Output and the user code execution. To deploy a function with Onedata as output storage provider you only have to specify an identifier, the URL of the Oneprovider host, your access token and the name of your Onedata space in the \"Storage\" tab of the service creation wizard: And the path where you want to store the files in the \"OUTPUTS\" tab: This means that scientists can store their output files on their Onedata space in the EGI DataHub for long-time persistence and easy sharing of experimental results between researchers.","title":"EGI DataHub"},{"location":"fdl/","text":"Functions Definition Language (OSCAR) Example: functions: oscar: - oscar-test: name: plants memory: 2Gi cpu: '1.0' image: grycap/oscar-theano-plants script: plants.sh input: - storage_provider: minio.default path: example-workflow/in output: - storage_provider: minio.default path: example-workflow/med - oscar-test: name: grayify memory: 1Gi cpu: '1.0' image: grycap/imagemagick script: grayify.sh input: - storage_provider: minio.default path: example-workflow/med output: - storage_provider: minio.default path: example-workflow/res - storage_provider: onedata.my_onedata path: result-example-workflow storage_providers: onedata: my_onedata: oneprovider_host: my_provider.com token: my_very_secret_token space: my_onedata_space Top level parameters Field Description functions Functions Mandatory parameter to define a Functions Definition Language file. Note that \"functions\" instead of \"services\" has been used in order to keep compatibility with SCAR storage_providers StorageProviders Parameter to define the credentials for the storage providers to be used in the services Functions Field Description oscar map[string] Service array Main object with the definition of the OSCAR services to be deployed. The components of the array are Service maps, where the key of every service is the identifier of the cluster where the service (defined as the value of the entry on the map) will be deployed. Service Field Description name string The name of the service image string Docker image for the service script string Local path to the user script to be executed in the service container memory string Memory limit for the service following the kubernetes format . Optional (default: 256Mi) cpu string CPU limit for the service following the kubernetes format . Optional (default: 0.2) log_level string Log level for the FaaS Supervisor. Available levels: NOTSET, DEBUG, INFO, WARNING, ERROR and CRITICAL. Optional (default: INFO) input StorageIOConfig array Array with the input configuration for the service. Optional output StorageIOConfig array Array with the output configuration for the service. Optional environment EnvVarsMap The user-defined environment variables assigned to the service. Optional StorageIOConfig Field Description storage_provider string Reference to the storage provider defined in storage_providers . This string is composed by the provider's name (minio, s3, onedata) and identifier (defined by the user), separated by a point (e.g. \"minio.myidentifier\") path string Path in the storage provider. In MinIO and S3 the first directory of the specified path is translated into the bucket's name (e.g. \"bucket/folder/subfolder\") suffix string array Array of suffixes for filtering the files to be uploaded. Only used in the output field. Optional prefix string array Array of prefixes for filtering the files to be uploaded. Only used in the output field. Optional EnvVarsMap Field Description Variables map[string]string Map to define the environment variables that will be available in the service container StorageProviders Field Description minio map[string] MinIOProvider Map to define the credentials for a MinIO storage provider, being the key the user-defined identifier for the provider s3 map[string] S3Provider Map to define the credentials for a Amazon S3 storage provider, being the key the user-defined identifier for the provider onedata map[string] OnedataProvider Map to define the credentials for a Onedata storage provider, being the key the user-defined identifier for the provider MinIOProvider Field Description endpoint string MinIO endpoint verify bool Verify MinIO's TLS certificates for HTTPS connections access_key string Access key of the MinIO server secret_key string Secret key of the MinIO server region string Region of the MinIO server S3Provider Field Description access_key string Access key of the AWS S3 service secret_key string Secret key of the AWS S3 service region string Region of the AWS S3 service OnedataProvider Field Description oneprovider_host string Endpoint of the Oneprovider token string Onedata access token space string Name of the Onedata space","title":"Functions definition Language"},{"location":"fdl/#functions-definition-language-oscar","text":"Example: functions: oscar: - oscar-test: name: plants memory: 2Gi cpu: '1.0' image: grycap/oscar-theano-plants script: plants.sh input: - storage_provider: minio.default path: example-workflow/in output: - storage_provider: minio.default path: example-workflow/med - oscar-test: name: grayify memory: 1Gi cpu: '1.0' image: grycap/imagemagick script: grayify.sh input: - storage_provider: minio.default path: example-workflow/med output: - storage_provider: minio.default path: example-workflow/res - storage_provider: onedata.my_onedata path: result-example-workflow storage_providers: onedata: my_onedata: oneprovider_host: my_provider.com token: my_very_secret_token space: my_onedata_space","title":"Functions Definition Language (OSCAR)"},{"location":"fdl/#top-level-parameters","text":"Field Description functions Functions Mandatory parameter to define a Functions Definition Language file. Note that \"functions\" instead of \"services\" has been used in order to keep compatibility with SCAR storage_providers StorageProviders Parameter to define the credentials for the storage providers to be used in the services","title":"Top level parameters"},{"location":"fdl/#functions","text":"Field Description oscar map[string] Service array Main object with the definition of the OSCAR services to be deployed. The components of the array are Service maps, where the key of every service is the identifier of the cluster where the service (defined as the value of the entry on the map) will be deployed.","title":"Functions"},{"location":"fdl/#service","text":"Field Description name string The name of the service image string Docker image for the service script string Local path to the user script to be executed in the service container memory string Memory limit for the service following the kubernetes format . Optional (default: 256Mi) cpu string CPU limit for the service following the kubernetes format . Optional (default: 0.2) log_level string Log level for the FaaS Supervisor. Available levels: NOTSET, DEBUG, INFO, WARNING, ERROR and CRITICAL. Optional (default: INFO) input StorageIOConfig array Array with the input configuration for the service. Optional output StorageIOConfig array Array with the output configuration for the service. Optional environment EnvVarsMap The user-defined environment variables assigned to the service. Optional","title":"Service"},{"location":"fdl/#storageioconfig","text":"Field Description storage_provider string Reference to the storage provider defined in storage_providers . This string is composed by the provider's name (minio, s3, onedata) and identifier (defined by the user), separated by a point (e.g. \"minio.myidentifier\") path string Path in the storage provider. In MinIO and S3 the first directory of the specified path is translated into the bucket's name (e.g. \"bucket/folder/subfolder\") suffix string array Array of suffixes for filtering the files to be uploaded. Only used in the output field. Optional prefix string array Array of prefixes for filtering the files to be uploaded. Only used in the output field. Optional","title":"StorageIOConfig"},{"location":"fdl/#envvarsmap","text":"Field Description Variables map[string]string Map to define the environment variables that will be available in the service container","title":"EnvVarsMap"},{"location":"fdl/#storageproviders","text":"Field Description minio map[string] MinIOProvider Map to define the credentials for a MinIO storage provider, being the key the user-defined identifier for the provider s3 map[string] S3Provider Map to define the credentials for a Amazon S3 storage provider, being the key the user-defined identifier for the provider onedata map[string] OnedataProvider Map to define the credentials for a Onedata storage provider, being the key the user-defined identifier for the provider","title":"StorageProviders"},{"location":"fdl/#minioprovider","text":"Field Description endpoint string MinIO endpoint verify bool Verify MinIO's TLS certificates for HTTPS connections access_key string Access key of the MinIO server secret_key string Secret key of the MinIO server region string Region of the MinIO server","title":"MinIOProvider"},{"location":"fdl/#s3provider","text":"Field Description access_key string Access key of the AWS S3 service secret_key string Secret key of the AWS S3 service region string Region of the AWS S3 service","title":"S3Provider"},{"location":"fdl/#onedataprovider","text":"Field Description oneprovider_host string Endpoint of the Oneprovider token string Onedata access token space string Name of the Onedata space","title":"OnedataProvider"},{"location":"license/","text":"License Apache License Version 2.0, January 2004 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION 1. Definitions. \"License\" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. \"Licensor\" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. \"Legal Entity\" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \"control\" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. \"You\" (or \"Your\") shall mean an individual or Legal Entity exercising permissions granted by this License. \"Source\" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. \"Object\" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. \"Work\" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). \"Derivative Works\" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. \"Contribution\" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \"submitted\" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \"Not a Contribution.\" \"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. 2. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. 3. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. 4. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) If the Work includes a \"NOTICE\" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. 5. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. 6. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. 7. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. 8. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. 9. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS APPENDIX: How to apply the Apache License to your work. To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets \"{}\" replaced with your own identifying information. (Don't include the brackets!) The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same \"printed page\" as the copyright notice for easier identification within third-party archives. Copyright 2018 GRyCAP - I3M - UPV Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","title":"License"},{"location":"license/#license","text":"Apache License Version 2.0, January 2004 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION 1. Definitions. \"License\" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. \"Licensor\" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. \"Legal Entity\" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \"control\" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. \"You\" (or \"Your\") shall mean an individual or Legal Entity exercising permissions granted by this License. \"Source\" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. \"Object\" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. \"Work\" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). \"Derivative Works\" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. \"Contribution\" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \"submitted\" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \"Not a Contribution.\" \"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. 2. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. 3. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. 4. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) If the Work includes a \"NOTICE\" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. 5. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. 6. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. 7. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. 8. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. 9. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS APPENDIX: How to apply the Apache License to your work. To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets \"{}\" replaced with your own identifying information. (Don't include the brackets!) The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same \"printed page\" as the copyright notice for easier identification within third-party archives. Copyright 2018 GRyCAP - I3M - UPV Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","title":"License"},{"location":"local-testing/","text":"Local Testing with kind The easiest way to test the OSCAR platform locally is using kind . Kind allows the deployment of Kubernetes clusters inside Docker containers and automatically configures kubectl to access them. Prerequisites Docker , required by kind to launch the Kubernetes nodes on containers. Kubectl to communicate with the Kubernetes cluster. Helm to easily deploy applications on Kubernetes. Kind to deploy the local Kubernetes cluster. Steps Create the cluster To create a single node cluster with MinIO and Ingress controller ports locally accessible, run: cat <<EOF | kind create cluster --config=- kind: Cluster apiVersion: kind.x-k8s.io/v1alpha4 nodes: - role: control-plane image: kindest/node:v1.18.6 kubeadmConfigPatches: - | kind: InitConfiguration nodeRegistration: kubeletExtraArgs: node-labels: \"ingress-ready=true\" extraPortMappings: - containerPort: 80 hostPort: 80 protocol: TCP - containerPort: 443 hostPort: 443 protocol: TCP - containerPort: 30300 hostPort: 30300 protocol: TCP EOF As some Linux distributions may have problems using the NFS server provisioner with the latest kind images, the version v1.18.6 has been used. Deploy NGINX Ingress To enable Ingress support for accessing the OSCAR server, we must deploy the NGINX Ingress : kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/static/provider/kind/deploy.yaml Deploy MinIO OSCAR depends on MinIO as storage provider and function trigger. The easy way to run MinIO in a Kubernetes cluster is by installing its helm chart . To install the helm MinIO repo and install the chart, run the following commands replacing <MINIO_PASSWORD> with a password: helm repo add minio https://helm.min.io helm install minio minio/minio --set accessKey=minio --set secretKey=<MINIO_PASSWORD> --set service.type=NodePort --set service.nodePort=30300 Note that the deployment has been configured to use the accessKey minio and the specified password as secretKey. The NodePort service type has been used in order to allow access from http://localhost:30300 Deploy NFS server provisioner NFS server provisioner is required for the creation of ReadWriteMany PersistentVolumes in the kind cluster. This is needed by the OSCAR services to mount the volume with the FaaS Supervisor inside the job containers. To deploy it you can use this chart executing: helm repo add kvaps https://kvaps.github.io/charts helm install nfs-server-provisioner kvaps/nfs-server-provisioner Deploy OSCAR First, create the oscar and oscar-svc namespaces by executing: kubectl apply -f https://raw.githubusercontent.com/grycap/oscar/master/deploy/yaml/oscar-namespaces.yaml Then, add the grycap helm repo and deploy by running the following commands replacing <OSCAR_PASSWORD> with a password of your choice and <MINIO_PASSWORD> with the MinIO accessKey: helm repo add grycap https://grycap.github.io/helm-charts/ helm install --namespace=oscar oscar grycap/oscar --set authPass=<OSCAR_PASSWORD> --set service.type=ClusterIP --set ingress.create=true --set volume.storageClassName=nfs --set minIO.endpoint=http://minio.default:9000 --set minIO.TLSVerify=false --set minIO.accessKey=minio --set minIO.secretKey=<MINIO_PASSWORD> Now you can access to the OSCAR web interface through https://localhost with user oscar and the specified password. Note that the OSCAR server has been configured to use the ClusterIP service of MinIO for internal communication. This blocks the MinIO section in the OSCAR web interface, so to download and upload files you must connect directly to MinIO ( http://localhost:30300 ). Delete the cluster Once you have finished testing the platform, you can remove the local kind cluster by executing: kind delete cluster Remember that if you have more than one cluster created, it may be required to set the --name flag to specify the name of the cluster to be deleted.","title":"Local testing"},{"location":"local-testing/#local-testing-with-kind","text":"The easiest way to test the OSCAR platform locally is using kind . Kind allows the deployment of Kubernetes clusters inside Docker containers and automatically configures kubectl to access them.","title":"Local Testing with kind"},{"location":"local-testing/#prerequisites","text":"Docker , required by kind to launch the Kubernetes nodes on containers. Kubectl to communicate with the Kubernetes cluster. Helm to easily deploy applications on Kubernetes. Kind to deploy the local Kubernetes cluster.","title":"Prerequisites"},{"location":"local-testing/#steps","text":"","title":"Steps"},{"location":"local-testing/#create-the-cluster","text":"To create a single node cluster with MinIO and Ingress controller ports locally accessible, run: cat <<EOF | kind create cluster --config=- kind: Cluster apiVersion: kind.x-k8s.io/v1alpha4 nodes: - role: control-plane image: kindest/node:v1.18.6 kubeadmConfigPatches: - | kind: InitConfiguration nodeRegistration: kubeletExtraArgs: node-labels: \"ingress-ready=true\" extraPortMappings: - containerPort: 80 hostPort: 80 protocol: TCP - containerPort: 443 hostPort: 443 protocol: TCP - containerPort: 30300 hostPort: 30300 protocol: TCP EOF As some Linux distributions may have problems using the NFS server provisioner with the latest kind images, the version v1.18.6 has been used.","title":"Create the cluster"},{"location":"local-testing/#deploy-nginx-ingress","text":"To enable Ingress support for accessing the OSCAR server, we must deploy the NGINX Ingress : kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/static/provider/kind/deploy.yaml","title":"Deploy NGINX Ingress"},{"location":"local-testing/#deploy-minio","text":"OSCAR depends on MinIO as storage provider and function trigger. The easy way to run MinIO in a Kubernetes cluster is by installing its helm chart . To install the helm MinIO repo and install the chart, run the following commands replacing <MINIO_PASSWORD> with a password: helm repo add minio https://helm.min.io helm install minio minio/minio --set accessKey=minio --set secretKey=<MINIO_PASSWORD> --set service.type=NodePort --set service.nodePort=30300 Note that the deployment has been configured to use the accessKey minio and the specified password as secretKey. The NodePort service type has been used in order to allow access from http://localhost:30300","title":"Deploy MinIO"},{"location":"local-testing/#deploy-nfs-server-provisioner","text":"NFS server provisioner is required for the creation of ReadWriteMany PersistentVolumes in the kind cluster. This is needed by the OSCAR services to mount the volume with the FaaS Supervisor inside the job containers. To deploy it you can use this chart executing: helm repo add kvaps https://kvaps.github.io/charts helm install nfs-server-provisioner kvaps/nfs-server-provisioner","title":"Deploy NFS server provisioner"},{"location":"local-testing/#deploy-oscar","text":"First, create the oscar and oscar-svc namespaces by executing: kubectl apply -f https://raw.githubusercontent.com/grycap/oscar/master/deploy/yaml/oscar-namespaces.yaml Then, add the grycap helm repo and deploy by running the following commands replacing <OSCAR_PASSWORD> with a password of your choice and <MINIO_PASSWORD> with the MinIO accessKey: helm repo add grycap https://grycap.github.io/helm-charts/ helm install --namespace=oscar oscar grycap/oscar --set authPass=<OSCAR_PASSWORD> --set service.type=ClusterIP --set ingress.create=true --set volume.storageClassName=nfs --set minIO.endpoint=http://minio.default:9000 --set minIO.TLSVerify=false --set minIO.accessKey=minio --set minIO.secretKey=<MINIO_PASSWORD> Now you can access to the OSCAR web interface through https://localhost with user oscar and the specified password. Note that the OSCAR server has been configured to use the ClusterIP service of MinIO for internal communication. This blocks the MinIO section in the OSCAR web interface, so to download and upload files you must connect directly to MinIO ( http://localhost:30300 ).","title":"Deploy OSCAR"},{"location":"local-testing/#delete-the-cluster","text":"Once you have finished testing the platform, you can remove the local kind cluster by executing: kind delete cluster Remember that if you have more than one cluster created, it may be required to set the --name flag to specify the name of the cluster to be deleted.","title":"Delete the cluster"},{"location":"usage/","text":"Using OSCAR through the web-based UI OSCAR allows the creation of serverless file-processing services based on container images. These services require a user-defined script with the commands responsible of the processing. The platform automatically mounts a volume on the containers with the FaaS Supervisor component, which is in charge of: Downloading the file that invokes the service and make it accessible through the INPUT_FILE_PATH environment variable. Execute the user-defined script. Upload the content of the output folder accessible via the TMP_OUTPUT_DIR environment variable. You can follow one of the examples in order to test the OSCAR framework for specific applications. We recommend you to start with the plant classification example detailed below. If you prefer to use the command-line interface rather than the web-based UI, there is an example in oscar-cli's repository . Login OSCAR is exposed via a Kubernetes ingress and it is accessible via the Kubernetes master node IP. If you deployed it using EC3 you can find the credentials here . After a correct login, you should see the main view: Deploying services In order to create a new service, you must click on the \"DEPLOY NEW SERVICE\" button and follow the wizard. Remember that a script must be provided for the processing of files. This script must use the environment variables INPUT_FILE_PATH and TMP_OUTPUT_DIR to refer to the input file and the folder where to save the results respectively: #!/bin/bash echo \"SCRIPT: Invoked classify_image.py. File available in $INPUT_FILE_PATH\" FILE_NAME=`basename \"$INPUT_FILE_PATH\"` OUTPUT_FILE=\"$TMP_OUTPUT_DIR/$FILE_NAME\" python2 /opt/plant-classification-theano/classify_image.py \"$INPUT_FILE_PATH\" -o \"$OUTPUT_FILE\" You must fill in the fields indicating the container image to use, the name of the service and the script file. In addition, you can add environment variables, specify the resources (RAM and CPUs) and choose the log level of the service. Next, the credentials of the storage providers to be used must be introduced. As the platform already has a MinIO deployment to operate, it is not necessary to enter its credentials for using it. Multiple MinIO, Onedata and Amazon S3 storage providers can be used. Remember to click the \"ADD\" button after completing each one. Then, click the \"NEXT\" button to go to the last section of the wizard. In this section, you must first choose the paths of the storage provider to be used as source of events, i.e. the input bucket and/or folder that will trigger the service. Only the minio.default provider can be used as input storage provider. After filling in each path, remember to click on the \"ADD INPUT\" button. Finally, the same must be done to indicate the output paths to be used in the desired storage providers. You can also indicate suffixes and/or prefixes to filter the files uploaded to each path by name. The resulting files can be stored in several storage providers, like in the following example, where they are stored in the MinIO server of the platform and in a Onedata space provided by the user. After clicking the \"SUBMIT\" button the new service will appear in the main view after a few seconds. Triggering the service HTTP endpoints OSCAR services can be invoked through auto-generated HTTP endpoints. Requests to these endpoints can be made in two ways: Synchronous through the path /run/<SERVICE_NAME> . This redirects the request to the OpenFaaS gateway in order to perform the processing. Asynchronous through the path /job/<SERVICE_NAME> . This mode is used to perform file-processing when files are uploaded to the input storage provider, creating a Kubernetes job per service invocation. The content of the HTTP request body will be stored as a file that will be available via the INPUT_FILE_PATH environment variable to process it. A detailed specification of the OSCAR's API and its different paths can be found here . Uploading files Once a service has been created, it can be invoked by uploading files to its input bucket/folder. This can be done through the MinIO web interface (accessible from the Kubernetes frontend IP, on port 30300 ) or from the \"Minio Storage\" section in the side menu of the OSCAR web interface. Expanding down that menu will list the buckets created and, by clicking on their name, you will be able to see their content, upload and download files. To upload files, first click on the \"SELECT FILES\" button and choose the files you want to upload from your computer. Once you have chosen the files to upload, simply click on the \"UPLOAD\" button and the file will be uploaded, raising an event that will trigger the service. Note that the web interface includes a preview button for some file formats, such as images. Service status and logs When files are being processed by a service, it is important to know their status, as well as to observe the execution logs for testing. For this purpose, OSCAR includes a log view, accessible by clicking on the \"LOGS\" button in a service from the main view. In this view you can see all the jobs created for a service, as well as their status (\"Pending\", \"Running\", \"Succeeded\" or \"Failed\") and their creation, start and finish time. To view the logs generated by a job, simply click on the drop-down button located on the right. The view also features options to refresh the status of one or all jobs, as well as to delete them. Downloading files from MinIO Downloading files from the platform's MinIO storage provider can also be done using the OSCAR web interface. To do it, simply select one or more files and click on the button \"DOWNLOAD OBJECT\" (or \"DOWNLOAD ALL AS A ZIP\" if several files have been selected). In the following picture you can see the preview of the resulting file after the execution triggered in the previous step. Deleting services Services can be deleted by clicking on the trash can icon from the main view. Once you have accepted the message shown in the image above, the service will be deleted after a few seconds.","title":"Using OSCAR through the web-based UI"},{"location":"usage/#using-oscar-through-the-web-based-ui","text":"OSCAR allows the creation of serverless file-processing services based on container images. These services require a user-defined script with the commands responsible of the processing. The platform automatically mounts a volume on the containers with the FaaS Supervisor component, which is in charge of: Downloading the file that invokes the service and make it accessible through the INPUT_FILE_PATH environment variable. Execute the user-defined script. Upload the content of the output folder accessible via the TMP_OUTPUT_DIR environment variable. You can follow one of the examples in order to test the OSCAR framework for specific applications. We recommend you to start with the plant classification example detailed below. If you prefer to use the command-line interface rather than the web-based UI, there is an example in oscar-cli's repository .","title":"Using OSCAR through the web-based UI"},{"location":"usage/#login","text":"OSCAR is exposed via a Kubernetes ingress and it is accessible via the Kubernetes master node IP. If you deployed it using EC3 you can find the credentials here . After a correct login, you should see the main view:","title":"Login"},{"location":"usage/#deploying-services","text":"In order to create a new service, you must click on the \"DEPLOY NEW SERVICE\" button and follow the wizard. Remember that a script must be provided for the processing of files. This script must use the environment variables INPUT_FILE_PATH and TMP_OUTPUT_DIR to refer to the input file and the folder where to save the results respectively: #!/bin/bash echo \"SCRIPT: Invoked classify_image.py. File available in $INPUT_FILE_PATH\" FILE_NAME=`basename \"$INPUT_FILE_PATH\"` OUTPUT_FILE=\"$TMP_OUTPUT_DIR/$FILE_NAME\" python2 /opt/plant-classification-theano/classify_image.py \"$INPUT_FILE_PATH\" -o \"$OUTPUT_FILE\" You must fill in the fields indicating the container image to use, the name of the service and the script file. In addition, you can add environment variables, specify the resources (RAM and CPUs) and choose the log level of the service. Next, the credentials of the storage providers to be used must be introduced. As the platform already has a MinIO deployment to operate, it is not necessary to enter its credentials for using it. Multiple MinIO, Onedata and Amazon S3 storage providers can be used. Remember to click the \"ADD\" button after completing each one. Then, click the \"NEXT\" button to go to the last section of the wizard. In this section, you must first choose the paths of the storage provider to be used as source of events, i.e. the input bucket and/or folder that will trigger the service. Only the minio.default provider can be used as input storage provider. After filling in each path, remember to click on the \"ADD INPUT\" button. Finally, the same must be done to indicate the output paths to be used in the desired storage providers. You can also indicate suffixes and/or prefixes to filter the files uploaded to each path by name. The resulting files can be stored in several storage providers, like in the following example, where they are stored in the MinIO server of the platform and in a Onedata space provided by the user. After clicking the \"SUBMIT\" button the new service will appear in the main view after a few seconds.","title":"Deploying services"},{"location":"usage/#triggering-the-service","text":"","title":"Triggering the service"},{"location":"usage/#http-endpoints","text":"OSCAR services can be invoked through auto-generated HTTP endpoints. Requests to these endpoints can be made in two ways: Synchronous through the path /run/<SERVICE_NAME> . This redirects the request to the OpenFaaS gateway in order to perform the processing. Asynchronous through the path /job/<SERVICE_NAME> . This mode is used to perform file-processing when files are uploaded to the input storage provider, creating a Kubernetes job per service invocation. The content of the HTTP request body will be stored as a file that will be available via the INPUT_FILE_PATH environment variable to process it. A detailed specification of the OSCAR's API and its different paths can be found here .","title":"HTTP endpoints"},{"location":"usage/#uploading-files","text":"Once a service has been created, it can be invoked by uploading files to its input bucket/folder. This can be done through the MinIO web interface (accessible from the Kubernetes frontend IP, on port 30300 ) or from the \"Minio Storage\" section in the side menu of the OSCAR web interface. Expanding down that menu will list the buckets created and, by clicking on their name, you will be able to see their content, upload and download files. To upload files, first click on the \"SELECT FILES\" button and choose the files you want to upload from your computer. Once you have chosen the files to upload, simply click on the \"UPLOAD\" button and the file will be uploaded, raising an event that will trigger the service. Note that the web interface includes a preview button for some file formats, such as images.","title":"Uploading files"},{"location":"usage/#service-status-and-logs","text":"When files are being processed by a service, it is important to know their status, as well as to observe the execution logs for testing. For this purpose, OSCAR includes a log view, accessible by clicking on the \"LOGS\" button in a service from the main view. In this view you can see all the jobs created for a service, as well as their status (\"Pending\", \"Running\", \"Succeeded\" or \"Failed\") and their creation, start and finish time. To view the logs generated by a job, simply click on the drop-down button located on the right. The view also features options to refresh the status of one or all jobs, as well as to delete them.","title":"Service status and logs"},{"location":"usage/#downloading-files-from-minio","text":"Downloading files from the platform's MinIO storage provider can also be done using the OSCAR web interface. To do it, simply select one or more files and click on the button \"DOWNLOAD OBJECT\" (or \"DOWNLOAD ALL AS A ZIP\" if several files have been selected). In the following picture you can see the preview of the resulting file after the execution triggered in the previous step.","title":"Downloading files from MinIO"},{"location":"usage/#deleting-services","text":"Services can be deleted by clicking on the trash can icon from the main view. Once you have accepted the message shown in the image above, the service will be deleted after a few seconds.","title":"Deleting services"}]}